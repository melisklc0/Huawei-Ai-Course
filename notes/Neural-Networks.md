# Neural Networks Quiz

## True or False
The neuron with computing capability at hidden layer is referred to as the computing unit.(1.0 points) - T

Increasing the number of parameters in layers of convolutional networks without increasing their depth will enhance the ability of our model.(1.0 points) - T

Using a deep model expresses a useful preference over the space of functions the model can learn.(1.0 points) -T

Dataset includes features and samples.A feature is used to describe the characteristics of an object.A sample is object or event with many features.(1.0 points) - T

Semi-supervised learning is on the part of the data has labels and others don't have their labels.(1.0 points) - T

If points on the line connected between any two points in the set are also in the set, the set is a convex set.(1.0 points) -T

The backpropagation algorithm can be used by the gradient descent optimization algorithm to adjust neural network weights.(1.0 points) -T

## Single Choice
Follow these operation, Which one is not right?(1.0 points) (A)
- A. BGD is more sensitive to noise than SGD.
- B. Mini-batch gradient descent (MBGD) is used small batch size training dataset to update the weights.
- C. All training data is used for each update to minimize the loss function in BGD.
- D. Only one sample point is considered during each update in SGD.

Which of the following methods can be used to implement backpropagation?(1.0 points) (A)
- A. Chain rule
- B. Computational graph
- C. Cost function
- D. Higher order differential

## Multiple Choices
For AI tasks. We can divide a task into four classes. Which calss is AI task.(1.0 points) (all)
- A. Supervised learning algorithms
- B. Semi-supervisor learning
- C. Reinforcement learning
- D. Unsupervised learning algorithms

Follow these operation, Which one is not right?(1.0 points) (all)
- A. ReLU has a derivative function and allows for backpropagation.
- B. ELU has an extra alpha constant which should be positive number.
- C. Softmax function calculates the probabilities of the event over 'n' different events.
- D. The activation function should be non-linear.